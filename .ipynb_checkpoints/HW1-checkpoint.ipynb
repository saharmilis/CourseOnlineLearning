{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Streaming & Online Learning - HW1\n",
    "by Millis Sahar, ID 300420379"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1 - Approximate Counter \n",
    "In our first class, we learned about approximate counting with ğ‘‚(ğ‘™ğ‘œğ‘” ğ‘™ğ‘œğ‘” ğ‘›) bits (for fixed\n",
    "estimation error, and fixed failure probability).\n",
    "This was done by keeping a counter X that is incremented, given a new event, only with probability $ \\frac{1}{2^x} $.\n",
    "The estimator ğ¶Ì‚ was taken to be $ 2^x-1 $.\n",
    "Denote the actual value of the counter by C. We showed in class, that ğ¶Ì‚ is an unbiased estimator, namely, ğ¸[ğ¶Ì‚ | ğ¶ = ğ‘] = ğ‘ . \n",
    "\n",
    "<br>\n",
    "\n",
    "###### 1. Show that ğ‘‰ğ‘ğ‘Ÿ(ğ¶Ì‚ |ğ¶ = ğ‘) = ğ‘‚(ğ‘)  \n",
    "Express $2^x$ as a function of $\\overset{âˆ§}{C}$ :\n",
    "$ C = 2^x-1 \\space \\Rightarrow \\space 2^x = C+1 \\space \\Rightarrow \\space 2^{2x} = 1.5C^2 +1.5C+1$ \n",
    "\n",
    "$ \\overset{âˆ§}{C} = 2^x - 1  \\Rightarrow \\overset{âˆ§}{C} +1 = 2^x $  \n",
    "$ (\\overset{âˆ§}{C} +1)^2 = (2^x)^2 \\Rightarrow \\overset{âˆ§}{C^2} + 2\\overset{âˆ§}{C} + 1  = 2^{2x}$\n",
    "\n",
    "<br>\n",
    "Proff:  \n",
    "$ Var(\\overset{âˆ§}{C}) = $  \n",
    "$ = E(\\overset{âˆ§}{C^2}) - E^2(\\overset{âˆ§}{C}) = $  \n",
    "$ = E\\big((2^x-1)^2\\big) - C^2 = $  \n",
    "$ = E\\big(2^{2x}-2*2^x+1\\big) - C^2 = $  \n",
    "$ = E\\big(2^{2x}\\big) -E\\big(2*2^x\\big) + E(1) - C^2 = $   \n",
    "Using the Expression of $2^x$ and $2^{2x}$ shown above  \n",
    "$ = E\\big(1.5\\overset{âˆ§}{C^2} + 1.5\\overset{âˆ§}{C} + 1\\big) -2E\\big(\\overset{âˆ§}{C} +1\\big) + E(1) - C^2 = $  \n",
    "$ = E\\big(1.5\\overset{âˆ§}{C^2}\\big) + 1.5E\\big(\\overset{âˆ§}{C}\\big) + E(1) -2E\\big(\\overset{âˆ§}{C}\\big) -2E(1) + E(1) - C^2 = $   \n",
    "$ = 1.5C^2 + 1.5C -2C - 1 + 1 + C^2 = $  \n",
    "$ = 0.5C^2 - 0.5C = $  \n",
    "$ = O\\big(0.5C^2 - 0.5C\\big) = $  \n",
    "$ = O\\big(C^2\\big)$  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Assume we want to count events minus anti-events (logins minus logouts, number of people entering minus number of people exiting).  This is also known as the turnstile model.   \n",
    "- John suggests to do this by storing two approximate counters, one for events and the other for non-events (and then subtracting their estimates).   \n",
    "- Elinoy argues that this is a waste of memory, and says â€œWhy do we need ğ‘™ğ‘œğ‘”ğ‘™ğ‘œğ‘”ğ‘› bits after seeing ğ‘› events and ğ‘› anti-events, giving a total of 0? Instead, letâ€™s figure out how to run X backwords given an anti-event!!!â€\n",
    "\n",
    "a. Show how Elinoy runs X backwards (in other words, show how to update X, given an anti-event, and prove that your result gives an unbiased estimator of the counter).\n",
    "\n",
    "As talked in class, Elinor is right. She could update X with the probability of $\\frac{1}{2^{x-1}}$.  \n",
    "I'll use mathematical induction to prove $E\\big(2^{x_k}\\big) = n-1$ : \n",
    "\n",
    "$ \\quad \\quad \\text{- Initial value: For K=0 and n=2(due to antievent must come after event):} $  \n",
    "$ \\quad \\quad E\\big(2^{x_0}\\big) = 2-1 $    \n",
    "$ \\quad \\quad E(1) = 1 $  \n",
    "$ \\quad \\quad 1 = 1 $  \n",
    "$ \\quad \\quad True!  $  \n",
    "\n",
    "$ \\quad \\quad \\text{- Hypothesis: }$  \n",
    "$ \\quad \\quad \\text{the statement }E\\big(2^{x_k}\\big) = n-1 \\text{ is true for any value n=k} $  \n",
    "\n",
    "$ \\quad \\quad \\text{- Now I'll prove the Hypothesis statement is true for n = k-1:   }E\\big(2^{x_{k-1}}\\big) = n-2 $     \n",
    "\n",
    "$ \\quad \\quad E\\big(2^{x_{k-1}}\\big) = $  \n",
    "$ \\quad \\quad  = \\sum\\limits_{i=0}^{\\infty} E\\big(2^{x_{k-1}} \\space | \\space x_k=i\\big)Pr(x_k=i) = $      \n",
    "$ \\quad \\quad  = \\sum\\limits_{i=0}^{\\infty}\\big( 2^{i-1}\\frac{1}{2^{i-1}} + 2^i(1-\\frac{1}{2^{i-1}})\\big)Pr(x_k=i) = $  \n",
    "$ \\quad \\quad  = \\sum\\limits_{i=0}^{\\infty}\\big( 2^{i-1}\\frac{1}{2^{i-1}} + 2^i(1-\\frac{2}{2^{i}})\\big)Pr(x_k=i) = $      \n",
    "$ \\quad \\quad  = \\sum\\limits_{i=0}^{\\infty}\\big( (1 + 2^i -2) \\big)Pr(x_k=i) = $      \n",
    "$ \\quad \\quad  = \\sum\\limits_{i=0}^{\\infty} (2^i-1) \\big)Pr(x_k=i) = $  \n",
    "$ \\quad \\quad  = \\sum\\limits_{i=0}^{\\infty}2^iPr(x_k=i) - \\sum\\limits_{i=0}^{\\infty}1Pr(x_k=i) = $    \n",
    "$ \\quad \\quad  = E\\big(2^{x_k}\\big) - E\\big(1\\big) = $    \n",
    "$ \\quad \\quad  \\text{by the Hypothesis}  $  \n",
    "$ \\quad \\quad  = (n-1) - 1 = $  \n",
    "$ \\quad \\quad  = n-2 $  \n",
    "$ \\quad \\quad Done!$  \n",
    "\n",
    "    As requested, I'll prove that this is an unbiased estimator of the counter:  \n",
    "$ \\quad \\quad E\\big(\\overset{~}{n}\\big) = $   \n",
    "$ \\quad \\quad = E\\big(2^x+1\\big) = $   \n",
    "$ \\quad \\quad = E\\big(2^x\\big) + E(1) = $   \n",
    "$ \\quad \\quad = (n-1) + 1  = $  \n",
    "$ \\quad \\quad = n $   \n",
    "$ \\quad \\quad Done!$  \n",
    "\n",
    "<br><br>\n",
    "\n",
    "b. What do you do when X goes back to zero?  \n",
    "\n",
    "When X equals to Zero I'll only INCREASE.  \n",
    "Because the   #LOGOUTS â‰¤ #LOGINS  by definition of the problem.  \n",
    "\n",
    "<br><br>\n",
    "\n",
    "c. Now analyze Elinoyâ€™s claim more carefully: If ğ‘› events arrive, followed by ğ‘› anti-events, did Elinoy really get rid of the ğ‘™ğ‘œğ‘” ğ‘™ğ‘œğ‘” ğ‘› bits? \n",
    "\n",
    "In that specific case, John and Elinor will use the same space - O(log n).\n",
    "In every case, the #Logouts won't be \"close\" to the #LOGINS Elinor won't be efficient as she claimd to be. \n",
    "But, this is the worst case for Elinor, therefore she will always surpass (or be equl) to John's way.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Assume that instead of advancing X with probability $\\frac{1}{2^x}$ (as we saw in class), we advance it with probability $\\frac{1}{(1+a)^x}$ , where a > 0 is a parameter.\n",
    "\n",
    "<br>\n",
    "\n",
    "a. What should be our new estimator ğ¶Ì‚ for the counter of elements (as a function\n",
    "of X)?  \n",
    "\n",
    "Define the new estimator : $ \\overset{âˆ§}{C} = \\frac{(1+a)^x-1}{a} $\n",
    "\n",
    "I'll use mathematical induction to prove : $E\\big((1+a)^x\\big)=an+1$\n",
    "\n",
    "- Initial value: For K=0 and $x_k$=0:  \n",
    "    $E\\big((1+a)^0\\big) = a*0 + 1 $  \n",
    "    $E(1) = 0+1$  \n",
    "    $1 = 1$  \n",
    "    True!\n",
    "\n",
    "- Hypothesis:  \n",
    "the statement $E\\big((1+a)^x_k\\big)=ak+1$ is true for any value n=k\n",
    "\n",
    "- Now I'll prove the Hypothesis statement is true for n = k+1: $E\\big((1+a)^{x_{k+1}}\\big)=a(k+1)+1$\n",
    "\n",
    "$ E\\big((1+a)^{x_{k+1}}\\big) = $  \n",
    "$ = \\sum\\limits_{i=0}^{\\infty} E\\big((1+a)^{x_k} \\space |\\space x_k=i\\big) Pr(x_k=i) = $   \n",
    "$ = \\sum\\limits_{i=0}^{\\infty} \\bigg( \\frac{1}{(a+1)^i}(a+1)^{i+1} + \\big(1-\\frac{1}{(a+1)^i}\\big)(a+1)^i\\bigg) Pr(x_k=i) = $  \n",
    "$ = \\sum\\limits_{i=0}^{\\infty} \\bigg( (a+1)^{i+1-i} + (a+1)^i -(a+1)^{i-i}\\bigg) Pr(x_k=i) = $   \n",
    "$ = \\sum\\limits_{i=0}^{\\infty} \\bigg( a+1 + (a+1)^i - 1\\bigg) Pr(x_k=i) = $   \n",
    "$ = \\sum\\limits_{i=0}^{\\infty} \\bigg( a+1 + (a+1)^i - 1\\bigg) Pr(x_k=i) = $  \n",
    "$ = \\sum\\limits_{i=0}^{\\infty} \\big( a + (a+1)^i \\big) Pr(x_k=i) = $  \n",
    "$ = \\sum\\limits_{i=0}^{\\infty} a Pr(x_k=i) + \\sum\\limits_{i=0}^{\\infty} (a+1)^i Pr(x_k=i) = $  \n",
    "$ = E\\big(a\\big) + E\\big( (a+1)^{x_k} \\big) = $  \n",
    "by the Hypothesis  \n",
    "$ = a + ak + 1 = $  \n",
    "$ = a(k+1) +1 $  \n",
    "Done!\n",
    "\n",
    "\n",
    "Also, just in case, I'll prove that this is an unbiased estimator of the counter:  \n",
    "$ E\\big(\\overset{âˆ§}{C}\\big) = $  \n",
    "$ = E\\bigg( \\frac{(1+a)^x-1}{a} \\bigg)= $  \n",
    "$ = \\frac{1}{a}E\\big((1+a)^x-1\\big) = $   \n",
    "$ = \\frac{1}{a}E\\big((1+a)^x\\big) - \\frac{1}{a}E\\big(1\\big) = $  \n",
    "$ = \\frac{1}{a} (an+1) - \\frac{1}{a} = $  \n",
    "$ = \\frac{an}{a} + \\frac{1}{a} - \\frac{1}{a} = $   \n",
    "$ = n$  \n",
    "Done!\n",
    "\n",
    "<br><br>\n",
    "\n",
    "b. What should be the value of parameter ğ‘ so that our estimate satisfies\n",
    "|ğ¶ âˆ’ ğ¶Ì‚ | â‰¤ ğœ€ğ¶ with constant probability (say, at least 2/3) (without\n",
    "averaging many estimators)?\n",
    "\n",
    "As this consept shown in class, I'll use Chebyshev's inequality guarantee in order to find the value that a is limited to, with the probability $\\frac{2}{3}$. And I'll start by finding $ Var\\big(\\overset{âˆ§}{C}\\big) $ .\n",
    "\n",
    "$ Var\\big(\\overset{âˆ§}{C}\\big) = $  \n",
    "$ E\\big(\\overset{âˆ§}{C^2}\\big) - E^2\\big(\\overset{âˆ§}{C}\\big) = $  \n",
    "by unbiased estimator(above)   \n",
    "$ = E\\big(\\overset{âˆ§}{C^2}\\big) - n^2 = $  \n",
    "$ = E\\bigg( \\big(\\frac{(1+a)^x-1}{a}\\big)^2 \\bigg) - n^2 = $  \n",
    "$ = E\\bigg( \\frac{1}{a^2} * \\big(  (1+a)^{2x} - 2(1+a)^x +1 \\big) \\bigg) - n^2 = $  \n",
    "$ = \\frac{1}{a^2} E\\bigg( (1+a)^{2x} - 2(1+a)^x +1 \\bigg) - n^2 = $  \n",
    "$ = \\frac{1}{a^2} E\\big( (1+a)^{2x} \\big) - \\frac{1}{a^2}E\\big(2(1+a)^x\\big) + \\frac{1}{a^2}E(1) - n^2 = $  \n",
    "\n",
    "by the calculations above of $E\\big( (1+a)^{x} \\big) = an+1$  and $E\\big( (1+a)^{2x} \\big) = 1.5(an)^2 + 1.5an + 1$  (like in Q1.1)   \n",
    "\n",
    "$ = \\frac{1}{a^2} \\big(1.5(an)^2 + 1.5an + a\\big) - \\frac{2}{a^2}(an+1) + \\frac{1}{a^2}E(1) - n^2 = $  \n",
    "\n",
    "$ = 1.5n^2 + 1.5\\frac{n}{a} + \\frac{1}{a} + \\frac{2n}{a^2} - \\frac{2}{a^2} + \\frac{1}{a^2} -n^2 = $  \n",
    "$ = 0.5n^2 + \\frac{1.5n+1}{a} + \\frac{2n-1}{a^2} \\leq $   \n",
    "And due to a>0 :   \n",
    "$ \\leq O\\big(n^2\\big) \\leq O\\big(an^2\\big) \\Rightarrow Var(x) \\leq O\\big( an^2 \\big) $\n",
    "\n",
    "And with Chebyshev's inequality guarantee:\n",
    "\n",
    "$\\frac{Var(x)}{\\epsilon^2 n^2} \\leq \\frac{1}{3}$  \n",
    "$\\frac{O\\big( an^2 \\big)}{\\epsilon^2 n^2} \\leq \\frac{1}{3}$  \n",
    "$\\frac{0.5an^2}{\\epsilon^2 n^2} \\leq \\frac{1}{3}$  \n",
    "$\\frac{an^2}{\\epsilon^2 n^2} \\leq \\frac{2}{3}$  \n",
    "$\\frac{a}{\\epsilon^2} \\leq \\frac{2}{3}$  \n",
    "$ a \\leq \\frac{2\\epsilon^2}{3}$  \n",
    "Done!\n",
    "\n",
    "<br><br>\n",
    "\n",
    "\n",
    "c. Derive a bound on the expected amount of space that such a scheme requires after approximately counting C events.\n",
    "\n",
    "After C events, meaning n=C :  \n",
    "$ (1+a)^{x_C} = aC + 1 $  \n",
    "$ \\log_{1+a}{(1+a)^{x_C}} = \\log_{1+a}{(aC+1)}$  \n",
    "$ x = \\log_{1+a}{aC+1} $   \n",
    "\n",
    "And for amount of space in bits:  $ \\log{\\log_{1+a}{(aC+1)}}$  \n",
    "And by the bound I'll need number of bits $\\leq \\log{\\log_{1+\\frac{2\\epsilon^2}{3}}{(\\frac{2\\epsilon^2C}{3})}}$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2 - ğ¹0 Estimator\n",
    "In class we saw Flajolet-Martin estimator for the number of distinct elements ğ¹0\n",
    "frequency\n",
    "moment).   \n",
    "The algorithms we discussed use an â€œidealizedâ€ hash functions that map each element to a floating point in [0,1] with theoretically infinite number of bits.  \n",
    "We will now see an example for another estimator which is using a â€œrealisticâ€ hash function.  \n",
    "Consider the following estimator for ğ¹Ì‚0 (originally from1).  \n",
    "Assume for convenience that $ğ‘š = 2^ğ‘‘$ for some d > 0:   \n",
    "\n",
    "â€¢ Pick a random hash function â„ âˆ¶ ğ‘†ğ‘¡ğ‘Ÿğ‘’ğ‘ğ‘š â†’ {0, 1}$^d$ . Namely, we map each element to a ğ‘‘ dimensional binary vector.  \n",
    "â€¢ For each element in the stream, ğ‘, define ğ‘Ÿ(ğ‘) = ğ‘šğ‘ğ‘¥{ğ‘— âˆˆ [ğ‘‘] | â„(ğ‘)1 = Â· Â· Â· = â„(ğ‘)ğ‘— = 0} .  \n",
    "â€¢ Let ğ‘… is max(ğ‘Ÿ(ğ‘)) for ğ‘âˆˆğ‘†ğ‘¡ğ‘Ÿğ‘’ğ‘ğ‘š (easy to translate this to a pseudocode)  \n",
    "â€¢ Estimate the number of distinct elements as ğ¹Ì‚0 = $2^ğ‘…$ .\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 1. Ignoring the space required for holding the hash function â„, how much space is required for running this algorithm? Explain. (Assume all counters are accurate, and that weâ€™re running only one instance of the algorithm).\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ O_{space} (Estimator) = \\sum Space_{Each \\space step} = $  \n",
    "$  = Space_{Hash Functions} + Space_{r(a)} + Space_{R} + Space_{\\overset{âˆ§}{F_0}} = $   \n",
    "Ignoring the space of the Hash functions  \n",
    "$ = 0 + Space_{r(a)} + Space_{R} + Space_{\\overset{âˆ§}{F_0}} = $  \n",
    "For the current element a comming from the stream:  \n",
    "$ = 0 + log(d) + + Space_{R} + Space_{\\overset{âˆ§}{F_0}} = $  \n",
    "Saving R as the maximun of r(a) until this point  \n",
    "$ = 0 + log(d) + + log(d) + Space_{\\overset{âˆ§}{F_0}} = $  \n",
    "Saving $\\overset{âˆ§}{F_0}$ as the predicted estemation   \n",
    "$ = 0 + log(d) + + log(d) + log(n) = $   \n",
    "$ = 2long(d) + log(n) \\leq O\\big(2log(d)\\big) \\leq O\\big(log(d)\\big) \\space or \\space O\\big(loglog(m)\\big) \\space of \\space bits$   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. For any element ğ‘ such that his histogram ğ‘“ğ‘ > 0, and any s â‰¥ 0, let ğ‘Šğ‘ ,ğ‘ be the indicator random variable that is equal to 1 if and only if ğ‘Ÿ(ğ‘) > ğ‘ , namely: \n",
    "\n",
    "\\begin{equation}\n",
    "\\\\ğ‘Š_{ğ‘ ,ğ‘} =\n",
    "\\begin{cases}\n",
    "      1 & s \\leq r(a)   \\\\\n",
    "      0 & r(a) < s \n",
    "\\end{cases} \\space and \\space let \\space Z_s = \\sum \\limits_{a:f_a>0} ğ‘Š_{ğ‘ ,ğ‘}\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### a. What is the variance and expectation of ğ‘Šğ‘ ,ğ‘?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ E\\big( W_{s,a} \\big) = $  \n",
    "$ = 1*Pr\\big(s \\leq r(a)\\big) + 0*Pr\\big(r(a)<s\\big) = $  \n",
    "$ = Pr\\big(s \\leq r(a)\\big) + 0 = $  \n",
    "$ = Pr\\big(s \\leq r(a)\\big) = $  \n",
    "$ = 0.5^s $  \n",
    "\n",
    "<br>\n",
    "\n",
    "$ Var\\big( W_{s,a} \\big) = $\n",
    "$ = E\\big( W_{s,a}^2 \\big) - E^2\\big( W_{s,a} \\big) = $  \n",
    "$ = 1^2*Pr\\big(s \\leq r(a)\\big) + 0^2*Pr\\big(r(a)<s\\big) - \\big(0.5^2\\big)^2 = $   \n",
    "$ = 0.5^s + 0 - 0.5^{2s} = $  \n",
    "$ = \\frac{1}{2^s} - \\frac{1}{2^{2s}}  = $  \n",
    "$ = \\frac{2^s - 1}{2^{2s}} $\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### b. What is the variance and expectation of ğ‘ğ‘ ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ Z_s = \\sum\\limits_{f_a}W_{s,a} $\n",
    "\n",
    "\n",
    "$ E\\big(Z_s\\big) = F_0 * E\\big(W_{s,a}\\big) = F_0 * 0.5^s = \\frac{F_0}{2^s}$\n",
    "\n",
    "Easy to distinguish, that this is a Binomial distribution.\n",
    "Due to the independence of each element a in the stream, and also the independence of the 'seccess' case $ s\\leq r(a) \\big) $ .  \n",
    "From defenition of X~Bin(n,p) $\\Rightarrow$ $Var\\big(X\\big) = np(1-p)$ :\n",
    "\n",
    "$ Var(Z_s) = F_0 * 0.5^s *\\big(1-0.5^s\\big) = F_0 \\frac{2^s-1}{2^{2s}}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c. Now notice that R equals exactly the maximal s such that ğ‘ğ‘  > 0. Use all this to prove that, if ğ‘$2^ğ‘ $ < ğ¹0 for some integer s, then Pr(ğ‘ğ‘  = 0) < $\\frac{1}{c}$    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ Pr(Z_s = 0) < \\frac{1}{c} $  \n",
    "I'll use Chebyshev:  \n",
    "$ Pr(Z_s = 0) = \\frac{Var(Z_s)}{E^2(Z_s)} = \\frac{F_0 \\frac{2^s-1}{2^{2s}}}{\\big(\\frac{F_0}{2^s}\\big)^2} = \\frac{F_0(2^s-1)}{F_0^2} = \\frac{2^s-1}{F_0} \\leq \\frac{2^2}{F_0} \\leq $    \n",
    "Using $c2^s < F_0 \\space \\Rightarrow \\space 2^s < \\frac{F_0}{c} $ :  \n",
    "$ \\leq \\frac{\\frac{F_0}{c}}{F_0} = \\frac{1}{c} $  \n",
    "Done!\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### d. Conclude that $F_0$ can be smaller than $\\frac{F_0}{c}$ with probability at most $\\frac{1}{c}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other words, I'll need to prove $P\\big(\\overset{âˆ§}{F_0} < \\frac{F_0}{c}\\big) \\leq \\frac{1}{c}$  \n",
    "Given that $\\overset{âˆ§}{F_0} = 2^R$ , I'll prove $P\\big(2^R < \\frac{F_0}{c}\\big) \\leq \\frac{1}{c}$ which is obviosly TRUE, due to the proof above stating that this $Pr\\big(Z_s=0\\big) < \\frac{1}{c}$ is always true for R which was the maximal s. Therefore the probability will be smaller for any smaller number s.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3 - ğ¹2 Estimator\n",
    "\n",
    "The 2nd frequency moment is denoted $ğ¹_2$, defined as âˆ‘ $ğ‘“_ğ‘^2$ ğ‘âˆˆğ‘†ğ‘¡ğ‘Ÿğ‘’ğ‘ğ‘š , where $ğ‘“_ğ‘$ denotes the histogram of element a.   \n",
    "\n",
    "We will learn in next lecture the following estimator ğ¹Ì‚2,defined as [âˆ‘ğ‘âˆˆğ‘†ğ‘¡ğ‘Ÿğ‘’ğ‘ğ‘š ğ‘ (ğ‘)ğ‘“ğ‘ ]$^2$ , where ğ‘  âˆ¶ ğ‘†ğ‘¡ğ‘Ÿğ‘’ğ‘ğ‘š â†’ {Â±1} is a random hash function (more precisely, we will only 4-wise independent is needed) mapping each element in the steam to 1 or -1.   \n",
    "This estimator is implemented simply by maintaining a counter C, initializing it to 0, and adding ğ‘ (ğ‘) upon arrival of new stream element a, and finally estimating ğ¹Ì‚$_2$ = ğ¶^2 . \n",
    "\n",
    "Using the usual trick, we will show in class that averaging $ğ‘‚\\big(\\frac{1}{\\epsilon^2}\\big)$ such independent\n",
    "estimators, then taking median of ğ‘‚(ğ‘™ğ‘œğ‘”$\\frac{1}{ğ›¿}$) of independent averages gives an estimator within\n",
    "relative error Îµ with probability at least 1 âˆ’ Î´.\n",
    "\n",
    "Note that, upon receiving element a, the final estimator (after taking the median of the averaging) requires updating $ğ‘¶\\big(\\frac{ğ’ğ’ğ’ˆ(\\frac{1}{ğœ¹})}{\\epsilon^2}\\big)$ counters.   \n",
    "We will now try to improve this.\n",
    "\n",
    "<br>\n",
    "\n",
    "Consider the following estimator instead:  \n",
    "â€¢ As before, choose a random ğ‘  âˆ¶ ğ‘†ğ‘¡ğ‘Ÿğ‘’ğ‘ğ‘š â†’ {Â±1} together with a random hash â„ âˆ¶ ğ‘†ğ‘¡ğ‘Ÿğ‘’ğ‘ğ‘š â†’ [ğ‘˜], where k is a parameter (recall that [k]={1,2,â€¦,k})    \n",
    "â€¢ Initialize k counters ğ¶1 ,â€¦ ,ğ¶ğ‘˜.  \n",
    "â€¢ Upon arrival of element ğ‘ğ‘– , perform the step: ğ¶â„(ğ‘ğ‘–) â† ğ¶â„(ğ‘ğ‘–) + ğ‘ (ğ‘ğ‘–).  \n",
    "â€¢ When the stream ends, the estimator is ğ¹Ì‚2 = $\\sum \\limits_{j=1}^{k}C^2_j$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Prove that ğ‘ƒğ‘Ÿ[|ğ¹Ì‚2 âˆ’ ğ¹2| > ğœ–ğ¹2] â‰¤13 as long as ğ‘˜ = ğ‘‚( $\\frac{1}{\\epsilon^2}$). You can make any randomness assumptions you want about the functions h and s.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll prove with chebyshev that $Pr(|\\overset{âˆ§}{F_2} - F_2|>\\epsilon F_2) \\leq \\frac{1}{3} \\space while \\space k=O\\big(\\frac{1}{\\epsilon^2}\\big)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ E\\big(\\overset{âˆ§}{F_2}\\big) = $  \n",
    "$ = E\\big(\\sum \\limits_{j=1}^{k} C_j^2\\big) = $  \n",
    "by expectation linearity  \n",
    "$ = \\sum \\limits_{j=1}^{k} E\\big( C_j^2\\big) = $  \n",
    "$ = \\sum \\limits_{j=1}^{k} \\bigg[ \\sum \\limits_{i=1}^{n} \\bigg(s(a_i)Pr\\big(h(a_i)=j\\big)\\bigg)^2  \\bigg] = $  \n",
    "$ = \\sum \\limits_{i=1}^{n} \\bigg[ \\sum \\limits_{j=1}^{k} \\bigg(s(a_i)^2Pr^2\\big(h(a_i)=j\\big)\\bigg)  \\bigg] = $  \n",
    "$ = \\sum \\limits_{i=1}^{n} \\bigg[ k*s^2(a_i)\\frac{1}{k}  \\bigg] = $  \n",
    "$ = \\sum \\limits_{i=1}^{n} s^2(a_i) = $  \n",
    "$ = \\sum \\limits_{i=1}^{n} F^2_{a_i} = $  \n",
    "by moments definition  \n",
    "$ = F_2 $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the complexity of the $Var()$'s calculation, I won't use Chebyshev, and use Chernoff bound:\n",
    "\n",
    "$Pr\\bigg(\\delta E(x) \\leq \\big|X-E(x)\\big|\\bigg) \\leq 2e^{\\frac{-E(x)\\delta^2}{3}} $\n",
    "\n",
    "but In order to do that I'll need to redefine the variables.\n",
    "\n",
    "Let $x_1,x_2 ... x_k$ be independent and identically distributed random variables with range between 0 and 1, and expectation E(x).\n",
    "\n",
    "so $x = \\frac{\\overset{âˆ§}{F_2}}{F_2} $  and $X = \\sum \\limits_{i=1}^{k}x_i = \\sum \\limits_{i=1}^{k}\\frac{C_i^2}{F_2} $ \n",
    "\n",
    "Also,  \n",
    "$E\\big( X \\big) = E\\big(\\sum \\limits_{i=1}^{k}x_i\\big) = E\\big(\\sum \\limits_{i=1}^{k}\\frac{C_i^2}{F_2}\\big) =  \\frac{1}{F_2}E\\big(\\sum \\limits_{i=1}^{k}C_i^2\\big) =   \\frac{1}{F_2}E\\big(\\overset{âˆ§}{F_2}\\big) = \\frac{1}{F_2} * F_2 = 1 $\n",
    "\n",
    "Which means I could use Chernoff with $0<\\epsilon<1$ as follows:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ Pr\\bigg(\\epsilon E(x) \\leq \\big|X-E(x)\\big|\\bigg) = $  \n",
    "$ = Pr\\bigg(\\epsilon*1 \\leq \\big|X-1\\big|\\bigg) = $  \n",
    "$ = Pr\\bigg(\\epsilon \\leq \\big|X-1\\big|\\bigg) = $  \n",
    "$ = Pr\\bigg(\\epsilon F_2 \\leq \\big|XF_2-1*F_2\\big|\\bigg) = $  \n",
    "$ = Pr\\bigg(\\epsilon F_2 \\leq \\big|XF_2-F_2\\big|\\bigg) = $  \n",
    "$ = Pr\\bigg(\\epsilon F_2 \\leq \\big|E(\\overset{âˆ§}{F_2})-f_2\\big|\\bigg) = $  \n",
    "$ = Pr\\bigg(\\epsilon E(\\overset{âˆ§}{F_2}) \\leq \\big|E(\\overset{âˆ§}{F_2})-F_2\\big|\\bigg) \\leq $  \n",
    "Choose $ k = \\frac{9}{\\epsilon^2} \\leq O\\big(\\frac{1}{\\epsilon^2}\\big) $  \n",
    "$ \\leq 2e^{\\frac{-1k\\epsilon^2}{3}} \\leq 2e^{\\frac{-\\frac{9}{\\epsilon^2}\\epsilon^2}{3}} \\leq  2e^{\\frac{-3\\epsilon^2}{\\epsilon^2}} \\leq   2e^{-3} \\leq  \\frac{2}{e^3} \\leq \\frac{1}{3} $   \n",
    "Done!!\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. What is the update time now, per stream element? \n",
    "\n",
    "All the oparations for every new elemnt coming for the Stream, is done by O(1) time.  \n",
    "So the update time of one element is O(1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On a persenal note: \n",
    "I had a really hard time solving few of the questions, and I got help from Aviv a number of time.  \n",
    "Also, we had a study group in which we shared ideas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3.1 NOTE:\n",
    "This is a proof I found online, and tried to follow it through, but it is so different then mine, that I added it too.\n",
    "Used it while I wanted to use the Variance in the bound. but it was too hard to follow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ E\\big( \\overset{âˆ§}{F_2} \\big) = $  \n",
    "$ = E\\big(\\sum \\limits_{j=1}^{k} C_j^2\\big) = $  \n",
    "$ = \\sum \\limits_{j=1}^{k} E\\big(C_j^2\\big) = $  \n",
    "$ = \\sum \\limits_{j=1}^{k}E \\bigg[ \\sum \\limits_{a \\in Stream}\\bigg( f_aS(a)Pr\\big(h(a)=j\\big)  \\bigg)^2 \\bigg] = $  \n",
    "$ =  \\sum \\limits_{j=1}^{k}  E\\bigg[ \\sum \\limits_{a=a}\\bigg( f_aS(a)Pr\\big(h(a)=j\\big)\\bigg)^2 + \\sum \\limits_{a\\neq a'} f_aS(a)Pr\\big(h(a)=j\\big)*f_{a'}S(a')Pr\\big(h(a')=j\\big)   \\bigg] = $  \n",
    "$ =   \\sum \\limits_{j=1}^{k} E\\bigg[ \\sum \\limits_{a=a}\\bigg( f_aS(a)Pr\\big(h(a)=j\\big)\\bigg)^2 \\bigg] +   \\sum \\limits_{j=1}^{k} E\\bigg[ \\sum \\limits_{a\\neq a'} f_aS(a)Pr\\big(h(a)=j\\big)*f_{a'}S(a')Pr\\big(h(a')=j\\big)   \\bigg] = $  \n",
    "$ =   \\sum \\limits_{j=1}^{k}  \\sum \\limits_{a=a} E\\bigg[ \\bigg( f_aS(a)Pr\\big(h(a)=j\\big)\\bigg)^2 \\bigg] +   \\sum \\limits_{j=1}^{k}  \\sum \\limits_{a\\neq a'}E\\bigg[  f_aS(a)Pr\\big(h(a)=j\\big)*f_{a'}S(a')Pr\\big(h(a')=j\\big)   \\bigg] = $  \n",
    "$ =   \\sum \\limits_{j=1}^{k} \\sum \\limits_{a=a} f_a^2 E\\bigg(  S(a)^2Pr^2\\big(h(a)=j\\big) \\bigg) + 0 = $  \n",
    "$ =   \\sum \\limits_{j=1}^{k} \\sum \\limits_{a=a} f_a^2 E\\bigg(  S(a)^2\\bigg)E\\bigg(Pr^2\\big(h(a)=j\\big) \\bigg) = $  \n",
    "$ =   \\sum \\limits_{j=1}^{k} \\sum \\limits_{a=a}f_a^2* 1*E\\bigg(Pr^2\\big(h(a)=j\\big) \\bigg) = $  \n",
    "$ =   \\sum \\limits_{j=1}^{k} \\sum \\limits_{a=a} f_a^2\\bigg(0*Pr^2\\big(h(a)=0\\big)\\bigg)\\bigg(1*Pr^2\\big(h(a)=1\\big)\\bigg) = $  \n",
    "$ =   \\sum \\limits_{j=1}^{k} \\sum \\limits_{a=a} f_a^2 * \\bigg( 1 * (\\frac{1}{k}) \\bigg) = $  \n",
    "$ =   \\sum \\limits_{j=1}^{k} \\sum \\limits_{a=a} f_a^2 \\frac{1}{k} = \\sum \\limits_{j=1}^{k} \\frac{F_2}{k} = k \\frac{F_2}{k}  = F_2 $\n",
    "Done!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ E\\big(\\overset{âˆ§}{F_2^2}\\big) = $  \n",
    "$ = E\\bigg( (\\sum \\limits_{j=1}^{k} C_j^2)^2 \\bigg) = $  \n",
    "$ = E\\bigg( \\sum \\limits_{j=1}^{k} C_j^2 * \\sum \\limits_{j=1}^{k} C_j^2 \\bigg) = $  \n",
    "As shown in class, I will Calculate for the 4 cases, but just 2 won't be Zero! when 2 pairs are equal or when all are equal.\n",
    "$ = E\\bigg( \\sum \\limits_{j=1}^{k} C_j^4 \\bigg) + E\\bigg(6\\sum \\limits_{j=1}^{k}\\sum\\limits_{i=1}^{n} C_j^2C_i^2 \\bigg) = $  \n",
    "by expectation linearity  \n",
    "$ = \\sum \\limits_{j=1}^{k} E\\big(  C_j^4 \\big) + 6E\\bigg(\\sum \\limits_{j=1}^{k}\\sum\\limits_{i=1}^{n} C_j^2C_i^2 \\bigg) = $  \n",
    "and by moments definition (and from class and help online)\n",
    "$ = F_4 + \\frac{F^2_2}{k^2}-2F_4 = \\frac{F^2_2}{k^2}-F_4$\n",
    "\n",
    "\n",
    "$ = F_4 - 2(F_2^2 - 2 + F_4^2) - F_2^2 $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ Var\\big(F_2\\big) = $   \n",
    "$ = E\\big(F_2^2\\big) - E^2\\big(F_2\\big) = $   \n",
    "$ = \\frac{F^2_2}{k^2}-F_4 - F_2^2 \\leq \\frac{F^2_2}{k^2} - F_2^2 \\leq \\frac{F^2_2 - k^2F_2^2}{k^2}  \\leq \\frac{F^2_2 - k^2F_2^2}{k^2}  $   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Pr\\bigg(a \\leq \\big|X-E(x)\\big|\\bigg) \\leq \\frac{var(x)}{a^2}$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
